{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 7장. 여러개 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 다중 분류 신경망 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassNetwork:\n",
    "    def __init__(self, units=10, batch_size=32, learing_rate=0.1, l1=0, l2=0):\n",
    "        self.units = units          # 은닉층의 뉴런 개수\n",
    "        self.batch_size = batch_size #배치크기\n",
    "        self.w1 = None #은닉층의 가중치\n",
    "        self.b1 = None #은닉층의 절편\n",
    "        self.w2 = None #출력층의 가중치\n",
    "        self.b2 = None #출력층의 절편\n",
    "        self.losses = [] #훈련 손실\n",
    "        self.val_losses = [] # 검증손실\n",
    "        self.lr = learing_rate #학습률\n",
    "        self.l1 = l1 # L1 손실 하이퍼파라미터\n",
    "        self.l2 = l2 # L2 손실 하이퍼파라미터\n",
    "    \n",
    "    def forpass(self, x):\n",
    "        z1 = np.dot(x, self.w1) + self.b1 # 첫번째 층의 선형 식을 계산\n",
    "        self.a1 = self.sigmoid(z1) #활성화 함수를 적용\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2 # 두 번째 층의 선형 식을 계산\n",
    "        return z2\n",
    "\n",
    "    def backprop(self, x, err):\n",
    "        m = len(x) #샘플 개수\n",
    "        # 출력층의 가중치와 절편에 대한 그래디언트 계산\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\n",
    "        b2_grad = np.sum(err) / m\n",
    "        # 시그모이드 함수까지 그래디언트 계산\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        # 은닉층의 가중치와 절편에 대한 그래디언트 계산\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        z = np.clip(z, -100, None)  # 안전한 np.exp() 계산을 위함\n",
    "        a = 1 / (1 + np.exp(-z))  # 시그모이드 계산\n",
    "        return a\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        #소프트맥스 함수\n",
    "        z = np.clip(z, -100, None)\n",
    "        exp_z = np.exp(z)\n",
    "        return exp_z / np.sum(exp_z, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    def init_weights(self, n_features, n_classes):\n",
    "        self.w1 = np.random.normal(0, 1,\n",
    "                                   (n_features, self.units)) # (특성 개수, 은닉층의 크기)\n",
    "        self.b1 = np.zeros(self.units)   # 은닉층의 크기\n",
    "        self.w2 = np.random.normal(0, 1,\n",
    "                                   (self.units, n_classes))  # (은닉층의 크기, 클래스 개수)\n",
    "        self.b2 = np.zeros(n_classes)\n",
    "\n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
    "        np.random.seed(42)\n",
    "        self.init_weights(x.shape[1], y.shape[1])  # 은닉층과 출력층의 가중치를 초기화\n",
    "        # epochs만큼 반복\n",
    "        for i in range(epochs):\n",
    "            loss = 0\n",
    "            print('.', end='')\n",
    "            # 제너레이터 함수에서 반환한 미니배치를 순환\n",
    "            for x_batch, y_batch in self.gen_batch(x, y):\n",
    "                a = self.training(x_batch, y_batch)\n",
    "                # 안전한 로그 계산을 위해 클리핑\n",
    "                a = np.clip(a, 1e-10, 1-1e-10)\n",
    "                # 로그 손실과 구제 손실을 더하여 리스트 추가\n",
    "                loss += np.sum(-y_batch*np.log(a))\n",
    "            self.losses.append((loss + self.reg_loss()) / len(x))\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "\n",
    "    # a미니 배치 제너레이터 함수\n",
    "    def gen_batch(self, x, y):\n",
    "        length = len(x)\n",
    "        bins = length // self.batch_size # 미니배치 횟수\n",
    "        if length % self.batch_size:\n",
    "            bins += 1                    # 나누어 떨어지지 않을 때\n",
    "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
    "        x = x[indexes]\n",
    "        y = y[indexes]\n",
    "        for i in range(bins):\n",
    "            start = self.batch_size * i\n",
    "            end = self.batch_size * (i + 1)\n",
    "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다.\n",
    "            \n",
    "    def training(self, x, y):\n",
    "        m = len(x)                # 샘플 개수를 저장합니다.\n",
    "        z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
    "        a = self.softmax(z)       # 활성화 함수를 적용합니다.\n",
    "        err = -(y - a)            # 오차를 계산합니다.\n",
    "        # 오차를 역전파하여 그래디언트를 계산합니다.\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        # 그래디언트에서 페널티 항의 미분 값을 뺍니다\n",
    "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
    "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
    "        # 은닉층의 가중치와 절편을 업데이트합니다.\n",
    "        self.w1 -= self.lr * w1_grad\n",
    "        self.b1 -= self.lr * b1_grad\n",
    "        # 출력층의 가중치와 절편을 업데이트합니다.\n",
    "        self.w2 -= self.lr * w2_grad\n",
    "        self.b2 -= self.lr * b2_grad\n",
    "        return a\n",
    "   \n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)          # 정방향 계산을 수행합니다.\n",
    "        return np.argmax(z, axis=1)  # 가장 큰 값의 인덱스를 반환합니다.\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
    "\n",
    "    def reg_loss(self):\n",
    "        # 은닉층과 출력층의 가중치에 규제를 적용합니다.\n",
    "        return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\n",
    "               self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))\n",
    "\n",
    "    def update_val_loss(self, x_val, y_val):\n",
    "        z = self.forpass(x_val)            # 정방향 계산을 수행합니다.\n",
    "        a = self.softmax(z)                # 활성화 함수를 적용합니다.\n",
    "        a = np.clip(a, 1e-10, 1-1e-10)     # 출력 값을 클리핑합니다.\n",
    "        # 크로스 엔트로피 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
    "        val_loss = np.sum(-y_val*np.log(a))\n",
    "        self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassNetwork:\n",
    "    \n",
    "    def __init__(self, units=10, batch_size=32, learning_rate=0.1, l1=0, l2=0):\n",
    "        self.units = units         # 은닉층의 뉴런 개수\n",
    "        self.batch_size = batch_size     # 배치 크기\n",
    "        self.w1 = None             # 은닉층의 가중치\n",
    "        self.b1 = None             # 은닉층의 절편\n",
    "        self.w2 = None             # 출력층의 가중치\n",
    "        self.b2 = None             # 출력층의 절편\n",
    "        self.a1 = None             # 은닉층의 활성화 출력\n",
    "        self.losses = []           # 훈련 손실\n",
    "        self.val_losses = []       # 검증 손실\n",
    "        self.lr = learning_rate    # 학습률\n",
    "        self.l1 = l1               # L1 손실 하이퍼파라미터\n",
    "        self.l2 = l2               # L2 손실 하이퍼파라미터\n",
    "\n",
    "    def forpass(self, x):\n",
    "        z1 = np.dot(x, self.w1) + self.b1        # 첫 번째 층의 선형 식을 계산합니다\n",
    "        self.a1 = self.sigmoid(z1)               # 활성화 함수를 적용합니다\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2  # 두 번째 층의 선형 식을 계산합니다.\n",
    "        return z2\n",
    "\n",
    "    def backprop(self, x, err):\n",
    "        m = len(x)       # 샘플 개수\n",
    "        # 출력층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\n",
    "        b2_grad = np.sum(err) / m\n",
    "        # 시그모이드 함수까지 그래디언트를 계산합니다.\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        # 은닉층의 가중치와 절편에 대한 그래디언트를 계산합니다.\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
    "        a = 1 / (1 + np.exp(-z))              # 시그모이드 계산\n",
    "        return a\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        # 소프트맥스 함수\n",
    "        z = np.clip(z, -100, None)            # 안전한 np.exp() 계산을 위해\n",
    "        exp_z = np.exp(z)\n",
    "        return exp_z / np.sum(exp_z, axis=1).reshape(-1, 1)\n",
    " \n",
    "    def init_weights(self, n_features, n_classes):\n",
    "        self.w1 = np.random.normal(0, 1, \n",
    "                                   (n_features, self.units))  # (특성 개수, 은닉층의 크기)\n",
    "        self.b1 = np.zeros(self.units)                        # 은닉층의 크기\n",
    "        self.w2 = np.random.normal(0, 1, \n",
    "                                   (self.units, n_classes))   # (은닉층의 크기, 클래스 개수)\n",
    "        self.b2 = np.zeros(n_classes)\n",
    "        \n",
    "    def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
    "        np.random.seed(42)\n",
    "        self.init_weights(x.shape[1], y.shape[1])    # 은닉층과 출력층의 가중치를 초기화합니다.\n",
    "        # epochs만큼 반복합니다.\n",
    "        for i in range(epochs):\n",
    "            loss = 0\n",
    "            print('.', end='')\n",
    "            # 제너레이터 함수에서 반환한 미니배치를 순환합니다.\n",
    "            for x_batch, y_batch in self.gen_batch(x, y):\n",
    "                a = self.training(x_batch, y_batch)\n",
    "                # 안전한 로그 계산을 위해 클리핑합니다.\n",
    "                a = np.clip(a, 1e-10, 1-1e-10)\n",
    "                # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
    "                loss += np.sum(-y_batch*np.log(a))\n",
    "            self.losses.append((loss + self.reg_loss()) / len(x))\n",
    "            # 검증 세트에 대한 손실을 계산합니다.\n",
    "            self.update_val_loss(x_val, y_val)\n",
    "\n",
    "    # 미니배치 제너레이터 함수\n",
    "    def gen_batch(self, x, y):\n",
    "        length = len(x)\n",
    "        bins = length // self.batch_size # 미니배치 횟수\n",
    "        if length % self.batch_size:\n",
    "            bins += 1                    # 나누어 떨어지지 않을 때\n",
    "        indexes = np.random.permutation(np.arange(len(x))) # 인덱스를 섞습니다.\n",
    "        x = x[indexes]\n",
    "        y = y[indexes]\n",
    "        for i in range(bins):\n",
    "            start = self.batch_size * i\n",
    "            end = self.batch_size * (i + 1)\n",
    "            yield x[start:end], y[start:end]   # batch_size만큼 슬라이싱하여 반환합니다.\n",
    "            \n",
    "    def training(self, x, y):\n",
    "        m = len(x)                # 샘플 개수를 저장합니다.\n",
    "        z = self.forpass(x)       # 정방향 계산을 수행합니다.\n",
    "        a = self.softmax(z)       # 활성화 함수를 적용합니다.\n",
    "        err = -(y - a)            # 오차를 계산합니다.\n",
    "        # 오차를 역전파하여 그래디언트를 계산합니다.\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        # 그래디언트에서 페널티 항의 미분 값을 뺍니다\n",
    "        w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\n",
    "        w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\n",
    "        # 은닉층의 가중치와 절편을 업데이트합니다.\n",
    "        self.w1 -= self.lr * w1_grad\n",
    "        self.b1 -= self.lr * b1_grad\n",
    "        # 출력층의 가중치와 절편을 업데이트합니다.\n",
    "        self.w2 -= self.lr * w2_grad\n",
    "        self.b2 -= self.lr * b2_grad\n",
    "        return a\n",
    "   \n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)          # 정방향 계산을 수행합니다.\n",
    "        return np.argmax(z, axis=1)  # 가장 큰 값의 인덱스를 반환합니다.\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
    "\n",
    "    def reg_loss(self):\n",
    "        # 은닉층과 출력층의 가중치에 규제를 적용합니다.\n",
    "        return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + \\\n",
    "               self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))\n",
    "\n",
    "    def update_val_loss(self, x_val, y_val):\n",
    "        z = self.forpass(x_val)            # 정방향 계산을 수행합니다.\n",
    "        a = self.softmax(z)                # 활성화 함수를 적용합니다.\n",
    "        a = np.clip(a, 1e-10, 1-1e-10)     # 출력 값을 클리핑합니다.\n",
    "        # 크로스 엔트로피 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
    "        val_loss = np.sum(-y_val*np.log(a))\n",
    "        self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_all.shape, y_train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> print(x_train_all.shape, y_train_all.shape)에서 출력된 결과 (60000, 28, 28)과 (60000,)는 두 데이터 배열 x_train_all과 y_train_all의 형태(shape)를 나타냅니다.\n",
    "\n",
    "> (60000, 28, 28): x_train_all는 3차원 배열이며, 이 형태는 60000개의 28x28 크기의 이미지로 구성되어 있음을 의미합니다. 여기서 60000은 이미지의 개수, 28x28은 각 이미지의 높이와 너비를 나타냅니다. 즉, 각 이미지는 28행 28열의 픽셀로 이루어져 있습니다.\n",
    "\n",
    "> (60000,): y_train_all는 1차원 배열이며, 60000개의 항목을 포함하고 있습니다. 각 항목은 x_train_all의 해당 이미지의 라벨을 나타냅니다.\n",
    "\n",
    "> 예를 들어 패션 MNIST 데이터셋에서는: x_train_all은 60000개의 28x28 픽셀의 그레이스케일 이미지로 구성된 훈련 이미지 데이터입니다.\n",
    "\n",
    "> y_train_all은 해당 이미지의 카테고리 라벨(0부터 9까지의 정수)를 포함하는 훈련 라벨 데이터입니다.\n",
    "\n",
    "> 따라서 이 정보를 바탕으로 x_train_all[0]은 첫 번째 이미지의 28x28 픽셀 데이터를, y_train_all[0]은 첫 번째 이미지의 라벨을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train_all[15], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0 2 7 2 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_all[:10])  #라벨링된거 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['티셔츠/윗도리', '바지', '스웨터', '드레스', '코트', '샌들', '셔츠', '스니커즈', '가방', '앵클부츠']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "티셔츠/윗도리\n"
     ]
    }
   ],
   "source": [
    "print(class_names[y_train_all[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800, 4800],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_val = x_val / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> x_train = x_train / 255와 x_val = x_val / 255로 데이터를 255로 나누는 것은 이미지 데이터를 정규화하는 표준적인 방법 중 하나입니다.\n",
    "\n",
    "> 이미지 데이터는 보통 각 픽셀의 강도를 0에서 255 사이의 정수로 나타냅니다. 여기서 0은 검은색을, 255는 흰색을 의미하며, 그 사이의 값은 다양한 그레이스케일 값을 의미합니다 (컬러 이미지의 경우 RGB 각 채널마다 동일한 범위를 갖습니다).\n",
    "\n",
    "> 255로 나눔으로써 데이터를 0과 1 사이의 범위로 스케일링하게 됩니다. 이러한 정규화는 다음과 같은 이유로 중요합니다:\n",
    "\n",
    "> 신경망 학습의 안정성: 머신러닝 모델, 특히 딥러닝 모델은 입력 데이터의 스케일에 민감합니다. 0과 1 사이의 작은 값을 가지는 입력 데이터는 모델의 학습을 안정화시키고 더 빠르게 수렴하게 합니다.\n",
    "\n",
    "> 가중치 초기화: 많은 딥러닝 모델의 가중치 초기화 방식은 0과 1 사이의 입력 데이터를 가정하고 설계되었습니다.\n",
    "\n",
    "> 활성화 함수: 여러 활성화 함수 (예: 시그모이드)는 0과 1 사이의 값에 최적화되어 있습니다. 입력 데이터의 스케일이 너무 크면 활성화 함수의 출력이 해당 함수의 한계값에 빠르게 포화될 수 있습니다.\n",
    "\n",
    "> 수치 안정성: 일관된 스케일의 데이터는 수치 연산에서의 오류나 불안정성을 줄일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 784)\n",
    "x_val = x_val.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "lb.fit_transform([0, 1, 3, 1])  # 원핫인코딩 / 0, 1, 3 을 각각 원핫인코딩하는것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical([0,1,3]) # 케라스 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0], y_train_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................"
     ]
    }
   ],
   "source": [
    "fc = MultiClassNetwork(units=100, batch_size=256) \n",
    "# `MultiClassNetwork` 클래스를 사용하여 다중 클래스 신경망을 생성합니다.\n",
    "# 이 신경망은 100개의 유닛과 배치 크기 256을 가집니다.\n",
    "fc.fit(x_train, y_train_encoded,\n",
    "       x_val=x_val, y_val=y_val_encoded, epochs=40)\n",
    "# 신경망을 훈련 데이터 `x_train` 및 `y_train_encoded`로 학습시킵니다.\n",
    "# `x_val` 및 `y_val_encoded`는 검증 데이터로 사용됩니다.\n",
    "# 신경망은 총 40 에포크 동안 학습됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fc.losses)\n",
    "plt.plot(fc.val_losses)\n",
    "plt.plot('loss')\n",
    "plt.plot('iteration')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3555833333333333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fc.score(x_val, y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, ..., 1, 5, 7], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(np.arange(12000)%10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> np.arange(12000) % 10:\n",
    "\n",
    "> np.arange(12000)는 0부터 11999까지의 정수 배열을 생성합니다.\n",
    "\n",
    "> % 10 연산은 각 원소를 10으로 나눈 나머지를 계산합니다. 따라서 결과 배열은 0부터 9까지의 숫자들이 1200번 반복되는 형태가 됩니다.\n",
    "\n",
    "> 예: [0, 1, 2, ..., 9, 0, 1, 2, ..., 9, ...] (이 패턴이 총 1200번 반복됨)\n",
    "\n",
    "> np.random.permutation(...):\n",
    "\n",
    "> 이 함수는 주어진 배열을 무작위로 섞습니다.\n",
    "\n",
    ">결과적으로 array([4, 6, 3, ..., 0, 6, 6], dtype=int32)는 0부터 9까지의 숫자들이 반복되는 배열을 무작위로 섞은 것\n",
    "\n",
    "> 라벨이나 데이터를 무작위로 섞을 때 사용 / 0부터 9까지의 숫자들이 균등하게 분포되어 있지만 무작위 순서로 배열\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10416666666666667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_val == np.random.permutation(np.arange(12000)%10)) / 12000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드는 y_val 배열의 라벨과 0부터 9까지의 무작위 순열을 가진 배열 간의 일치도를 계산하는 것입니다. 구체적으로 코드를 단계별로 살펴보겠습니다.\n",
    "\n",
    "np.random.permutation(np.arange(12000) % 10):\n",
    "\n",
    "0부터 11999까지의 정수 배열을 생성한 다음, 각 원소를 10으로 나눈 나머지를 계산합니다. 결과적으로, 0부터 9까지의 숫자들이 1200번 반복되는 배열이 생성됩니다.\n",
    "생성된 배열을 무작위로 섞습니다.\n",
    "y_val == np.random.permutation(np.arange(12000) % 10):\n",
    "\n",
    "y_val 배열과 위에서 생성한 무작위 배열을 원소별로 비교합니다. 두 배열의 같은 위치에 있는 원소가 동일하면 True, 그렇지 않으면 False를 반환합니다.\n",
    "np.sum(...):\n",
    "\n",
    "True는 1로, False는 0으로 간주되므로, np.sum()은 True의 개수, 즉 두 배열에서 일치하는 원소의 개수를 반환합니다.\n",
    "np.sum(...) / 12000:\n",
    "\n",
    "전체 원소 12000개 중에서 일치하는 원소의 비율을 계산합니다. 이 값은 두 배열 간의 일치도를 나타냅니다.\n",
    "코드의 전반적인 의미는, y_val 배열의 라벨이 0부터 9까지의 숫자로 이루어진 무작위 배열과 얼마나 일치하는지를 계산하는 것입니다. 이런 연산을 통해, 만약 y_val이 무작위로 라벨링된 데이터라면, 일치도는 대략 10% (즉, 1/10) 근처의 값을 가질 것으로 예상됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07-2 텐서플로와 케라스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword argument(s) in `compile()`: ({'metrices'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\whgml\\Desktop\\메타버스아카데미_DS\\이미지처리\\딥러닝_CNN\\딥러닝_날코딩_7.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/whgml/Desktop/%EB%A9%94%ED%83%80%EB%B2%84%EC%8A%A4%EC%95%84%EC%B9%B4%EB%8D%B0%EB%AF%B8_DS/%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%B2%98%EB%A6%AC/%EB%94%A5%EB%9F%AC%EB%8B%9D_CNN/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EB%82%A0%EC%BD%94%EB%94%A9_7.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mcompile(optimizer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msgd\u001b[39;49m\u001b[39m'\u001b[39;49m, loss\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcategorical_crossentropy\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/whgml/Desktop/%EB%A9%94%ED%83%80%EB%B2%84%EC%8A%A4%EC%95%84%EC%B9%B4%EB%8D%B0%EB%AF%B8_DS/%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%B2%98%EB%A6%AC/%EB%94%A5%EB%9F%AC%EB%8B%9D_CNN/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EB%82%A0%EC%BD%94%EB%94%A9_7.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m               metrices\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\whgml\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\whgml\\miniconda3\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py:2983\u001b[0m, in \u001b[0;36mModel._validate_compile\u001b[1;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[0;32m   2981\u001b[0m invalid_kwargs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(kwargs) \u001b[39m-\u001b[39m {\u001b[39m'\u001b[39m\u001b[39msample_weight_mode\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m   2982\u001b[0m \u001b[39mif\u001b[39;00m invalid_kwargs:\n\u001b[1;32m-> 2983\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid keyword argument(s) in `compile()`: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2984\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m(invalid_kwargs,)\u001b[39m}\u001b[39;00m\u001b[39m. Valid keyword arguments include \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2985\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcloning\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexperimental_run_tf_function\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdistribute\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2986\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget_tensors\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msample_weight_mode\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   2988\u001b[0m \u001b[39m# Model must be created and compiled with the same DistStrat.\u001b[39;00m\n\u001b[0;32m   2989\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39mand\u001b[39;00m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mhas_strategy():\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile()`: ({'metrices'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\"."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrices=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
